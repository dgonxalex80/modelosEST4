---
title: <span style="color:#034a94">**Análisis de Conglomerados**</span>
author: "Modelos Estadísticos para la toma de decisiones"
output:
  html_document:
    code_folding: hide
    css: style.css
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,comment = NA)
library(paqueteMODELOS)
library(ade4)
library(ggrepel)
library(xtable)
library(scatterplot3d)

id= 1:8
empresa =data.frame(inv.pub = c(16,12,10,12,45,50,45,50),
ventas =c(10,14,22,25,10,14,25,27) )
rownames(empresa) = c("E1","E2","E3","E4","E5","E6","E7", "E8")
empresa_z =scale(empresa)
empresa_z = as.data.frame(empresa_z)
```


</br></br>

# <span style="color:#034a94">**Introducción**</span>

</br>

El análisis de conglomerados, también conocido como **clustering**, es un método estadístico usado para agrupar objetos similares en función de sus características. Mediante este análisis se logra identificar grupos muy parecidos (homogéneos) de objetos o individuos. Dentro de cada grupo los objetos son más similares entre sí que con los de otros grupos. El análisis de conglomerados implica la selección de un conjunto de variables para medir las características de los objetos o individuos, y luego aplicar un algoritmo de agrupamiento para clarificarlos en conglomerados.  Los algoritmos de agrupamiento utilizados pueden ser jerárquicos o no jerárquicos, dependiendo de si los grupos se construyen de forma iterativa a partir de subgrupos más pequeños.

</br></br>

# <span style="color:#034a94">**Supuestos y requisitos**</span>

</br>

El análisis de conglomerados se basa en calcular distancias entre los individuos métricas  a partir de la matriz de datos $X$. Una vez encontrados los conglomerados o grupos se procede a representarlos en un plano factorial. Supone por tanto el conocimiento previo de la presencia de conglomerados o por lo menos sospecha de presencia de grupos, aunque no se tenga claramente una distribución a priori.

</br></br>

# <span style="color:#034a94">**Conceptos asociados**</span>

</br>


### <span style="color:#034a94">**Estandarización**</span>

Debido a la diferencias en las escalas de las variables empleadas en el análisis, es necesario colocarlas en una sola escala, para lo cual  a cada variables se le resta el valor de su media y el resultado se divide por su desviación estándar. El producto de esta trasformación es una variable con media $0$ y varianza $1$.


$$
z= \dfrac{x - \bar{x}}{\sigma}
$$
</br>

### <span style="color:#034a94">**Distancia**</span>

La distancia entre dos observaciones  es una medida de sus diferencias. El AC emplea varias medias de distancias como :

* <span style="color:#034a94">**Distancia euclidiana**</span>

$$
D_{ij} = \sqrt{\sum_{p=1}^{k} (x_{ip}-x_{jp})^{2}}
$$

* <span style="color:#034a94">**Distancia de Manhattan**</span> 

$$
D_{ij} = \sum_{p=1}^{k} \big|x_{ip}-x_{jp}\big|^{n}
$$


* <span style="color:#034a94">**Distancia de Minkowski**</span>


$$
D_{ij} =\Big[\big|x_{ip}-x_{jp}\big|^{n}  \Big]^{1/n}
$$
</br></br>

### <span style="color:#034a94">**Agrupamiento**</span>

Mediante este procedimiento son asignadas las observaciones a los grupos o conglomerados  

</br></br>

### <span style="color:#034a94">**Criterios de calidad**</span> 

Utilizados para evaluar la bondad del agrupamiento resultante del análisis. Algunos de los criterios más comunes incluyen:

* **Suma de cuadrados dentro del cluster** ($SSC$), que mide cuanto varían las observaciones dentro de cada conglomerado y se mide sumando las distancias entre cada observación y el centroide de su conglomerado. 

</br>

* **Suma de cuadrados entre clusters** ($SSB$), que mide la variabilidad entre los conglomerados,permitiendo valorar la calidad del agrupamiento.   

</br>

* **Indice de Rand ajustado**, corresponde a un indicador para evaluar la calidad del agrupamiento. Este indice varia entre $-1$ y $1$. Valores cercanos a  $1$ indica alta similitud entre los grupos, mientras que valores cercanos a $-1$ indica que los grupos o conglomerados formados son muy diferentes. Valores cercanos a0 indican que los agrupamientos pueden ser productos del azar 


</br></br>

### <span style="color:#034a94">**Centros del conglomerado**</span>

Es la media de los valores de las variables de todos los objetos o casos de cada uno de los conglomerados

</br></br>

### <span style="color:#034a94">**Dendograma**</span>

Corresponde a la representación gráfica de los resultados obtenidos en el AC, en un plano donde el eje vertical indica las distancias en las que se unen o separan los conglomerados y en el eje horizontal los objetos o individuos.


</br></br>

### <span style="color:#034a94">**Matriz de coeficientes de semejanza y distancias**</span>

Corresponde a una matriz diagonal inferior que contiene  las distancias entre pares de objetos o casos.


</br></br>

## <span style="color:#034a94">**Modelo**</span>

</br>

Existen dos tipos de clasificación automática: los **métodos no jerárquicos** los cuales se basan en encontrar la mejor partición del conjunto de individuos en $q$ clases, en donde sus centros de gravedad se eligen en un inicio de forma aleatoria. Por otra parte están los **métodos jerárquicos** en los cuales se construye un dendograma en el cual se forman los grupos de individuos más parecidos, esto permite determinar el número de clases que se usarán en el método no jerárquico. 

</br>

Mediante el análisis de conglomerados se desea clasificar a los distintos individuos u observaciones en grupos muy homogéneos, pero heterogéneos entre ellos. Para realizar este objetivo se utilizan métricas que permiten calcular el grado de asociación (similitud o disimilitud) entre dos observaciones, dentro de las  más usada  está la **distancia euclidiana** entre los dos puntos, la cual está dado por:

</br>

$$
d(x_i, x_j) = \sqrt{\sum_{p=1}^{m} (x_{ip}-x_{jp})^{2}}
$$



</br>

En donde $x_i$ y $x_j$ son individuos con $m$ variables, de esta forma podremos obtener los dos primeros individuos que más se parezcan entre sí, formarán el primer grupo. Sean entonces $h = \{x_i, x_j\}$ un grupo y $x_k$ un individuo, con los que se puede calcular la distancia entre el grupo y el individuo de la forma: $d(h, x_k) = min\{d(x_i,x_k), d(x_j, x_k)\}$. Además de el método descrito, hay otras formas de medir la proximidad entre elementos como pueden ser el salto mínimo (single linkage), salto máximo, salto promedio y agregación de Ward. 

</br></br>



